{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS, OWL, Literal, URIRef\n",
    "from rdflib.namespace import XSD, RDF, SDO, RDFS\n",
    "\n",
    "KG = Namespace(\"http://kg-course/model-management/\")\n",
    "BIBO = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "\n",
    "\n",
    "g = Graph()\n",
    "g.bind(\"kg\", KG)\n",
    "g.bind(\"bibo\", BIBO)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"schema1\", SCHEMA)\n",
    "g.bind(\"xsd\", XSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models class and its properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N2e2ac2cc0c454ea49cbc9587f7405699 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class\n",
    "g.add((KG.Model, RDF.type, RDFS.Class))\n",
    "g.add((KG.Model, RDFS.label, Literal(\"Model\", lang=\"en\")))\n",
    "g.add((KG.Model, RDFS.comment, Literal(\"NLP, Computer Vision, Reinforcement Learning etc. models\", lang=\"en\")))\n",
    "\n",
    "# Model name\n",
    "g.add((KG.name, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.name, RDFS.label, Literal(\"Model name\", lang=\"en\")))\n",
    "g.add((KG.name, RDFS.domain, KG.Model))\n",
    "g.add((KG.name, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Model creator\n",
    "g.add((KG.creator, RDF.type, OWL.ObjectProperty))\n",
    "g.add((KG.creator, RDFS.label, Literal(\"Model creator\", lang=\"en\")))\n",
    "g.add((KG.creator, RDFS.domain, KG.Model))\n",
    "g.add((KG.creator, RDFS.range, SCHEMA.Person))\n",
    "\n",
    "# Creation date\n",
    "g.add((KG.created_at, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.created_at, RDFS.label, Literal(\"Creation date\", lang=\"en\")))\n",
    "g.add((KG.created_at, RDFS.domain, KG.Model))\n",
    "g.add((KG.created_at, RDFS.range, XSD.dateTime))\n",
    "\n",
    "# Downloads\n",
    "g.add((KG.downloads, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.downloads, RDFS.label, Literal(\"Number of times a model has been downloaded\", lang=\"en\")))\n",
    "g.add((KG.downloads, RDFS.domain, KG.Model))\n",
    "g.add((KG.downloads, RDFS.range, XSD.integer))\n",
    "\n",
    "# Task\n",
    "g.add((KG.task, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.task, RDFS.label, Literal(\"Model task\", lang=\"en\")))\n",
    "g.add((KG.task, RDFS.comment, Literal(\"The task the model is designed to perform\", lang=\"en\")))\n",
    "g.add((KG.task, RDFS.domain, KG.Model))\n",
    "g.add((KG.task, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# hasPaper property\n",
    "g.add((KG.hasPaper, RDF.type, OWL.ObjectProperty))\n",
    "g.add((KG.hasPaper, RDFS.label, Literal(\"has Paper\", lang=\"en\")))\n",
    "g.add((KG.hasPaper, RDFS.comment, Literal(\"The ID of the paper that the model is based on or described in\", lang=\"en\")))\n",
    "g.add((KG.hasPaper, RDFS.domain, KG.Model))\n",
    "g.add((KG.hasPaper, RDFS.range, KG.Paper))\n",
    "\n",
    "# Base model\n",
    "g.add((KG.base_model, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.base_model, RDFS.label, Literal(\"Base model\", lang=\"en\")))\n",
    "g.add((KG.base_model, RDFS.comment, Literal(\"The base model the model is built on\", lang=\"en\")))\n",
    "g.add((KG.base_model, RDFS.domain, KG.Model))\n",
    "g.add((KG.base_model, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Language\n",
    "g.add((KG.language, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.language, RDFS.label, Literal(\"Supported languages\", lang=\"en\")))\n",
    "g.add((KG.language, RDFS.comment, Literal(\"The languages the model supports (e.g. IT, EN, etc.)\", lang=\"en\")))\n",
    "g.add((KG.language, RDFS.domain, KG.Model))\n",
    "g.add((KG.language, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# hasEvaluationMetric property to link model to evaluation metrics\n",
    "g.add((KG.hasEvaluationMetric, RDF.type, OWL.ObjectProperty))\n",
    "g.add((KG.hasEvaluationMetric, RDFS.label, Literal(\"has Evaluation Metric\", lang=\"en\")))\n",
    "g.add((KG.hasEvaluationMetric, RDFS.domain, KG.Model))\n",
    "g.add((KG.hasEvaluationMetric, RDFS.range, KG.EvaluationMetric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics class and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N2e2ac2cc0c454ea49cbc9587f7405699 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ----------------- Evaluation Metric class -----------------#\n",
    "\n",
    "g.add((KG.EvaluationMetric, RDF.type, RDFS.Class))\n",
    "g.add((KG.EvaluationMetric, RDFS.label, Literal(\"Evaluation Metric\", lang=\"en\")))\n",
    "g.add((KG.EvaluationMetric, RDFS.comment, Literal(\"The evaluation metric used to evaluate the model\", lang=\"en\")))\n",
    "\n",
    "#----------------- Evaluation Metric properties -----------------#\n",
    "\n",
    "# Task type\n",
    "g.add((KG.taskType, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.taskType, RDFS.label, Literal(\"Task on which the model was evaluated\", lang=\"en\")))\n",
    "g.add((KG.taskType, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.taskType, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Dataset name\n",
    "g.add((KG.datasetName, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.datasetName, RDFS.label, Literal(\"Dataset Name\", lang=\"en\")))\n",
    "g.add((KG.datasetName, RDFS.comment, Literal(\"The name of the dataset used to evaluate the model, e.g. MNIST, IMDB, or custom\", lang=\"en\")))\n",
    "g.add((KG.datasetName, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.datasetName, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Metric type\n",
    "g.add((KG.metricType, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.metricType, RDFS.label, Literal(\"Metric Type\", lang=\"en\")))\n",
    "g.add((KG.metricType, RDFS.comment, Literal(\"The type of evaluation metric used, e.g. accuracy, F1 score, etc.\", lang=\"en\")))\n",
    "g.add((KG.metricType, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.metricType, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Metric value\n",
    "g.add((KG.metricValue, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.metricValue, RDFS.label, Literal(\"Metric Value\", lang=\"en\")))\n",
    "g.add((KG.metricValue, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.metricValue, RDFS.range, XSD.float))\n",
    "\n",
    "# Metric error\n",
    "g.add((KG.metricError, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.metricError, RDFS.label, Literal(\"Metric Error\", lang=\"en\")))\n",
    "g.add((KG.metricError, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.metricError, RDFS.range, XSD.float))\n",
    "\n",
    "# Metric mean\n",
    "g.add((KG.metricMean, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.metricMean, RDFS.label, Literal(\"Metric Mean\", lang=\"en\")))\n",
    "g.add((KG.metricMean, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.metricMean, RDFS.range, XSD.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N2e2ac2cc0c454ea49cbc9587f7405699 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------- Paper class -----------------#\n",
    "g.add((KG.Paper, RDF.type, OWL.Class))\n",
    "g.add((KG.Paper, RDFS.label, Literal(\"Scientific paper\", lang=\"en\")))\n",
    "g.add((KG.Paper, RDFS.comment, Literal(\"A scientific paper that describes a model or research work\", lang=\"en\")))\n",
    "g.add((KG.Paper, OWL.equivalentClass, BIBO.Article))\n",
    "g.add((SCHEMA.Person, RDFS.comment, Literal(\"A person, company, or organization that created the model\", lang=\"en\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N2e2ac2cc0c454ea49cbc9587f7405699 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination='./output/graph/ontology.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Graph construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N2e2ac2cc0c454ea49cbc9587f7405699 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv(\"./data/merged-dataset.csv\")\n",
    "paper_resources = {}\n",
    "\n",
    "for model_id, group in merged.groupby(\"id_x\"):\n",
    "    first_row = group.iloc[0]\n",
    "    model_uri = URIRef(KG + first_row[\"id_x\"])\n",
    "    g.add((model_uri, RDF.type, KG.Model))\n",
    "    g.add((model_uri, KG.name, Literal(first_row[\"id_x\"].split(\"/\")[1])))\n",
    "    g.add((model_uri, KG.creator, Literal(first_row[\"author\"])))\n",
    "    g.add((model_uri, KG.created_at, Literal(first_row[\"created_at\"], datatype=XSD.dateTime)))\n",
    "    g.add((model_uri, KG.downloads, Literal(first_row[\"downloads\"], datatype=XSD.integer)))\n",
    "    if not pd.isna(first_row[\"pipeline_tag\"]):\n",
    "        g.add((model_uri, KG.task, Literal(first_row[\"pipeline_tag\"])))\n",
    "    \n",
    "    if not pd.isna(first_row[\"base_model\"]):\n",
    "        base_model = first_row[\"base_model\"]\n",
    "        if \"/\" in base_model:\n",
    "            base_model = base_model.split(\"/\")[1]\n",
    "        g.add((model_uri, KG.base_model, Literal(base_model)))\n",
    "    \n",
    "    language_string = first_row[\"language\"]\n",
    "    if not pd.isna(language_string) and language_string.strip():\n",
    "        language_list = [lang.strip() for lang in language_string.split(\",\") if lang.strip()]\n",
    "        for lang in language_list:\n",
    "            g.add((model_uri, KG.language, Literal(lang)))\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        metrics_list = json.loads(row[\"evaluation_metrics\"])\n",
    "        for metric in metrics_list:\n",
    "            metric_uri = URIRef(KG + \"EvaluationMetric/\" + str(uuid.uuid4()))\n",
    "            g.add((metric_uri, RDF.type, KG.EvaluationMetric))\n",
    "            g.add((metric_uri, KG.taskType, Literal(metric[\"task_type\"])))\n",
    "            g.add((metric_uri, KG.datasetName, Literal(metric[\"dataset_name\"])))\n",
    "            if metric.get(\"metric_type\"):\n",
    "                g.add((metric_uri, KG.metricType, Literal(metric[\"metric_type\"])))\n",
    "            if metric.get(\"metric_value\"):\n",
    "                g.add((metric_uri, KG.metricValue, Literal(metric[\"metric_value\"], datatype=XSD.float)))\n",
    "            else:\n",
    "                if metric.get(\"metric_mean\"):\n",
    "                    g.add((metric_uri, KG.metricMean, Literal(metric[\"metric_mean\"], datatype=XSD.float)))\n",
    "                if metric.get(\"metric_error\"):\n",
    "                    g.add((metric_uri, KG.metricError, Literal(metric[\"metric_error\"], datatype=XSD.float)))\n",
    "            g.add((model_uri, KG.hasEvaluationMetric, metric_uri))\n",
    "    \n",
    "    unique_papers = group['id_y'].dropna().unique()  \n",
    "    for paper_id in unique_papers:\n",
    "        paper_id_str = str(paper_id).strip()\n",
    "        if paper_id_str == \"\":\n",
    "            continue\n",
    "        if paper_id_str not in paper_resources:\n",
    "            paper_uri = URIRef(KG + \"Paper/\" + paper_id_str)\n",
    "            paper_resources[paper_id_str] = paper_uri\n",
    "            g.add((paper_uri, RDF.type, KG.Paper))\n",
    "            g.add((paper_uri, BIBO.identifier, Literal(paper_id_str)))\n",
    "            authors = group.iloc[0].get(\"authors\")\n",
    "            if pd.notna(authors):\n",
    "                authors = authors.strip()\n",
    "                g.add((paper_uri, BIBO.authorList, Literal(authors)))\n",
    "            title = group.iloc[0].get(\"title\")\n",
    "            if pd.notna(title):\n",
    "                title = title.strip()\n",
    "                g.add((paper_uri, BIBO.title, Literal(title, lang=\"en\")))\n",
    "            summary = group.iloc[0].get(\"summary\")  \n",
    "            if pd.notna(summary) and summary.strip():\n",
    "                g.add((paper_uri, BIBO.abstract, Literal(summary, lang=\"en\")))\n",
    "        else:\n",
    "            paper_uri = paper_resources[paper_id_str]\n",
    "        g.add((model_uri, KG.hasPaper, paper_uri))\n",
    "\n",
    "g.serialize(destination=\"./output/graph/models-metrics-papers.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143170\n"
     ]
    }
   ],
   "source": [
    "print(len(g))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
