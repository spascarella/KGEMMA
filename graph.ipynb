{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS, OWL, Literal, URIRef\n",
    "from rdflib.namespace import XSD, RDF, SDO, RDFS\n",
    "\n",
    "KG = Namespace(\"http://kg-course/model-management/\")\n",
    "BIBO = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "SCHEMA = Namespace(\"http://schema.org/\")\n",
    "\n",
    "\n",
    "g = Graph()\n",
    "g.bind(\"kg\", KG)\n",
    "g.bind(\"bibo\", BIBO)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"schema1\", SCHEMA)\n",
    "g.bind(\"xsd\", XSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models class and its properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N064bdd83fcbe46b494f192e550663925 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class\n",
    "g.add((KG.Model, RDF.type, RDFS.Class))\n",
    "g.add((KG.Model, RDFS.label, Literal(\"Model\", lang=\"en\")))\n",
    "g.add((KG.Model, RDFS.comment, Literal(\"NLP, Computer Vision, Reinforcement Learning etc. models\", lang=\"en\")))\n",
    "\n",
    "# Model name\n",
    "g.add((KG.name, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.name, RDFS.label, Literal(\"Model name\", lang=\"en\")))\n",
    "g.add((KG.name, RDFS.domain, KG.Model))\n",
    "g.add((KG.name, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Model creator\n",
    "g.add((KG.creator, RDF.type, OWL.ObjectProperty))\n",
    "g.add((KG.creator, RDFS.label, Literal(\"Model creator\", lang=\"en\")))\n",
    "g.add((KG.creator, RDFS.domain, KG.Model))\n",
    "g.add((KG.creator, RDFS.range, SCHEMA.Person))\n",
    "\n",
    "# Creation date\n",
    "g.add((KG.created_at, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.created_at, RDFS.label, Literal(\"Creation date\", lang=\"en\")))\n",
    "g.add((KG.created_at, RDFS.domain, KG.Model))\n",
    "g.add((KG.created_at, RDFS.range, XSD.dateTime))\n",
    "\n",
    "# Downloads\n",
    "g.add((KG.downloads, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.downloads, RDFS.label, Literal(\"Number of times a model has been downloaded\", lang=\"en\")))\n",
    "g.add((KG.downloads, RDFS.domain, KG.Model))\n",
    "g.add((KG.downloads, RDFS.range, XSD.integer))\n",
    "\n",
    "# Task\n",
    "g.add((KG.task, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.task, RDFS.label, Literal(\"Model task\", lang=\"en\")))\n",
    "g.add((KG.task, RDFS.comment, Literal(\"The task the model is designed to perform\", lang=\"en\")))\n",
    "g.add((KG.task, RDFS.domain, KG.Model))\n",
    "g.add((KG.task, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# hasPaper property\n",
    "g.add((KG.hasPaper, RDF.type, OWL.ObjectProperty))\n",
    "g.add((KG.hasPaper, RDFS.label, Literal(\"has Paper\", lang=\"en\")))\n",
    "g.add((KG.hasPaper, RDFS.comment, Literal(\"The ID of the paper that the model is based on or described in\", lang=\"en\")))\n",
    "g.add((KG.hasPaper, RDFS.domain, KG.Model))\n",
    "g.add((KG.hasPaper, RDFS.range, KG.Paper))\n",
    "\n",
    "# Base model\n",
    "g.add((KG.base_model, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.base_model, RDFS.label, Literal(\"Base model\", lang=\"en\")))\n",
    "g.add((KG.base_model, RDFS.comment, Literal(\"The base model the model is built on\", lang=\"en\")))\n",
    "g.add((KG.base_model, RDFS.domain, KG.Model))\n",
    "g.add((KG.base_model, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Language\n",
    "g.add((KG.language, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.language, RDFS.label, Literal(\"Supported languages\", lang=\"en\")))\n",
    "g.add((KG.language, RDFS.comment, Literal(\"The languages the model supports (e.g. IT, EN, etc.)\", lang=\"en\")))\n",
    "g.add((KG.language, RDFS.domain, KG.Model))\n",
    "g.add((KG.language, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# hasEvaluationMetric property to link model to evaluation metrics\n",
    "g.add((KG.hasEvaluationMetric, RDF.type, OWL.ObjectProperty))\n",
    "g.add((KG.hasEvaluationMetric, RDFS.label, Literal(\"has Evaluation Metric\", lang=\"en\")))\n",
    "g.add((KG.hasEvaluationMetric, RDFS.domain, KG.Model))\n",
    "g.add((KG.hasEvaluationMetric, RDFS.range, KG.EvaluationMetric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics class and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N064bdd83fcbe46b494f192e550663925 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ----------------- Evaluation Metric class -----------------#\n",
    "\n",
    "g.add((KG.EvaluationMetric, RDF.type, RDFS.Class))\n",
    "g.add((KG.EvaluationMetric, RDFS.label, Literal(\"Evaluation Metric\", lang=\"en\")))\n",
    "g.add((KG.EvaluationMetric, RDFS.comment, Literal(\"The evaluation metric used to evaluate the model\", lang=\"en\")))\n",
    "\n",
    "#----------------- Evaluation Metric properties -----------------#\n",
    "\n",
    "# Task type\n",
    "g.add((KG.taskType, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.taskType, RDFS.label, Literal(\"Task on which the model was evaluated\", lang=\"en\")))\n",
    "g.add((KG.taskType, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.taskType, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Dataset name\n",
    "g.add((KG.datasetName, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.datasetName, RDFS.label, Literal(\"Dataset Name\", lang=\"en\")))\n",
    "g.add((KG.datasetName, RDFS.comment, Literal(\"The name of the dataset used to evaluate the model, e.g. MNIST, IMDB, or custom\", lang=\"en\")))\n",
    "g.add((KG.datasetName, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.datasetName, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Metric type\n",
    "g.add((KG.metricType, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.metricType, RDFS.label, Literal(\"Metric Type\", lang=\"en\")))\n",
    "g.add((KG.metricType, RDFS.comment, Literal(\"The type of evaluation metric used, e.g. accuracy, F1 score, etc.\", lang=\"en\")))\n",
    "g.add((KG.metricType, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.metricType, RDFS.range, RDFS.Literal))\n",
    "\n",
    "# Metric value\n",
    "g.add((KG.metricValue, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.metricValue, RDFS.label, Literal(\"Metric Value\", lang=\"en\")))\n",
    "g.add((KG.metricValue, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.metricValue, RDFS.range, XSD.float))\n",
    "\n",
    "# Metric error\n",
    "g.add((KG.metricError, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.metricError, RDFS.label, Literal(\"Metric Error\", lang=\"en\")))\n",
    "g.add((KG.metricError, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.metricError, RDFS.range, XSD.float))\n",
    "\n",
    "# Metric mean\n",
    "g.add((KG.metricMean, RDF.type, OWL.DatatypeProperty))\n",
    "g.add((KG.metricMean, RDFS.label, Literal(\"Metric Mean\", lang=\"en\")))\n",
    "g.add((KG.metricMean, RDFS.domain, KG.EvaluationMetric))\n",
    "g.add((KG.metricMean, RDFS.range, XSD.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N064bdd83fcbe46b494f192e550663925 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------- Paper class -----------------#\n",
    "g.add((KG.Paper, RDF.type, OWL.Class))\n",
    "g.add((KG.Paper, RDFS.label, Literal(\"Scientific paper\", lang=\"en\")))\n",
    "g.add((KG.Paper, RDFS.comment, Literal(\"A scientific paper that describes a model or research work\", lang=\"en\")))\n",
    "g.add((KG.Paper, OWL.equivalentClass, BIBO.Article))\n",
    "g.add((SCHEMA.Person, RDFS.comment, Literal(\"A person, company, or organization that created the model\", lang=\"en\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N064bdd83fcbe46b494f192e550663925 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination='./output/graph/ontology.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Graph construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataframe = pd.read_csv(\"./data/merged-dataset.csv\")\\ndataframe = (dataframe.groupby(\"id_x\"))\\ndisplay(dataframe.head())\\n\\nfor index, row in dataframe.iterrows():\\n    model_uri = URIRef(KG + row[\"id\"])\\n    g.add((model_uri, RDF.type, KG.Model))\\n    g.add((model_uri, KG.name, Literal(row[\"id\"].split(\"/\")[1])))\\n    g.add((model_uri, KG.creator, Literal(row[\"author\"])))\\n    g.add((model_uri, KG.created_at, Literal(row[\"created_at\"], datatype=XSD.dateTime)))\\n    g.add((model_uri, KG.downloads, Literal(row[\"downloads\"], datatype=XSD.integer)))\\n\\n    if not pd.isna(row[\"pipeline_tag\"]):\\n       g.add((model_uri, KG.task, Literal(row[\"pipeline_tag\"])))\\n\\n    if not pd.isna(row[\"base_model\"]):\\n        if \"/\" in row[\"base_model\"]:\\n            row[\"base_model\"] = row[\"base_model\"].split(\"/\")[1]\\n            g.add((model_uri, KG.base_model, Literal(row[\"base_model\"])))\\n        else:\\n            g.add((model_uri, KG.base_model, Literal(row[\"base_model\"])))\\n    language_string = row[\"language\"]\\n\\n    if pd.isna(language_string):\\n        pass\\n    else:\\n        language_list = [aid.strip() for aid in language_string.split(\",\") if aid.strip()] \\n        if len(language_list) == 1:\\n            g.add((model_uri, KG.language, Literal(language_list[0])))\\n        elif len(language_list) > 1:\\n            for lang in language_list:\\n                g.add((model_uri, KG.language, Literal(lang)))\\n    \\n    metrics_list = json.loads(row[\"evaluation_metrics\"])\\n    for metric in metrics_list:\\n        metric_uri = URIRef(KG + \"EvaluationMetric_\" + str(uuid.uuid4()))\\n        g.add((metric_uri, RDF.type, KG.EvaluationMetric))\\n        g.add((metric_uri, KG.taskType, Literal(metric[\"task_type\"])))\\n        g.add((metric_uri, KG.datasetName, Literal(metric[\"dataset_name\"])))\\n        if metric.get(\"metric_type\"):\\n            g.add((metric_uri, KG.metricType, Literal(metric[\"metric_type\"])))\\n        if metric.get(\"metric_value\"):\\n            g.add((metric_uri, KG.metricValue, Literal(metric[\"metric_value\"], datatype=XSD.float)))\\n        else:\\n            if metric.get(\"metric_mean\"):\\n                g.add((metric_uri, KG.metricMean, Literal(metric[\"metric_mean\"], datatype=XSD.float)))\\n            if metric.get(\"metric_error\"):\\n                g.add((metric_uri, KG.metricError, Literal(metric[\"metric_error\"], datatype=XSD.float)))\\n        \\n        g.add((model_uri, KG.hasEvaluationMetric, metric_uri))\\n\\ng.serialize(destination=\"./output/graph/models-metrics.ttl\", format=\"turtle\")'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dataframe = pd.read_csv(\"./data/merged-dataset.csv\")\n",
    "dataframe = (dataframe.groupby(\"id_x\"))\n",
    "display(dataframe.head())\n",
    "\n",
    "for index, row in dataframe.iterrows():\n",
    "    model_uri = URIRef(KG + row[\"id\"])\n",
    "    g.add((model_uri, RDF.type, KG.Model))\n",
    "    g.add((model_uri, KG.name, Literal(row[\"id\"].split(\"/\")[1])))\n",
    "    g.add((model_uri, KG.creator, Literal(row[\"author\"])))\n",
    "    g.add((model_uri, KG.created_at, Literal(row[\"created_at\"], datatype=XSD.dateTime)))\n",
    "    g.add((model_uri, KG.downloads, Literal(row[\"downloads\"], datatype=XSD.integer)))\n",
    "\n",
    "    if not pd.isna(row[\"pipeline_tag\"]):\n",
    "       g.add((model_uri, KG.task, Literal(row[\"pipeline_tag\"])))\n",
    "\n",
    "    if not pd.isna(row[\"base_model\"]):\n",
    "        if \"/\" in row[\"base_model\"]:\n",
    "            row[\"base_model\"] = row[\"base_model\"].split(\"/\")[1]\n",
    "            g.add((model_uri, KG.base_model, Literal(row[\"base_model\"])))\n",
    "        else:\n",
    "            g.add((model_uri, KG.base_model, Literal(row[\"base_model\"])))\n",
    "    language_string = row[\"language\"]\n",
    "\n",
    "    if pd.isna(language_string):\n",
    "        pass\n",
    "    else:\n",
    "        language_list = [aid.strip() for aid in language_string.split(\",\") if aid.strip()] \n",
    "        if len(language_list) == 1:\n",
    "            g.add((model_uri, KG.language, Literal(language_list[0])))\n",
    "        elif len(language_list) > 1:\n",
    "            for lang in language_list:\n",
    "                g.add((model_uri, KG.language, Literal(lang)))\n",
    "    \n",
    "    metrics_list = json.loads(row[\"evaluation_metrics\"])\n",
    "    for metric in metrics_list:\n",
    "        metric_uri = URIRef(KG + \"EvaluationMetric_\" + str(uuid.uuid4()))\n",
    "        g.add((metric_uri, RDF.type, KG.EvaluationMetric))\n",
    "        g.add((metric_uri, KG.taskType, Literal(metric[\"task_type\"])))\n",
    "        g.add((metric_uri, KG.datasetName, Literal(metric[\"dataset_name\"])))\n",
    "        if metric.get(\"metric_type\"):\n",
    "            g.add((metric_uri, KG.metricType, Literal(metric[\"metric_type\"])))\n",
    "        if metric.get(\"metric_value\"):\n",
    "            g.add((metric_uri, KG.metricValue, Literal(metric[\"metric_value\"], datatype=XSD.float)))\n",
    "        else:\n",
    "            if metric.get(\"metric_mean\"):\n",
    "                g.add((metric_uri, KG.metricMean, Literal(metric[\"metric_mean\"], datatype=XSD.float)))\n",
    "            if metric.get(\"metric_error\"):\n",
    "                g.add((metric_uri, KG.metricError, Literal(metric[\"metric_error\"], datatype=XSD.float)))\n",
    "        \n",
    "        g.add((model_uri, KG.hasEvaluationMetric, metric_uri))\n",
    "\n",
    "g.serialize(destination=\"./output/graph/models-metrics.ttl\", format=\"turtle\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N064bdd83fcbe46b494f192e550663925 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv(\"./data/merged-dataset.csv\")\n",
    "i = 0\n",
    "paper_resources = {}\n",
    "\n",
    "for model_id, group in merged.groupby(\"id_x\"):\n",
    "    first_row = group.iloc[0]\n",
    "    model_uri = URIRef(KG + first_row[\"id_x\"])\n",
    "    g.add((model_uri, RDF.type, KG.Model))\n",
    "    g.add((model_uri, KG.name, Literal(first_row[\"id_x\"].split(\"/\")[1])))\n",
    "    g.add((model_uri, KG.creator, Literal(first_row[\"author\"])))\n",
    "    g.add((model_uri, KG.created_at, Literal(first_row[\"created_at\"], datatype=XSD.dateTime)))\n",
    "    g.add((model_uri, KG.downloads, Literal(first_row[\"downloads\"], datatype=XSD.integer)))\n",
    "    if not pd.isna(first_row[\"pipeline_tag\"]):\n",
    "        g.add((model_uri, KG.task, Literal(first_row[\"pipeline_tag\"])))\n",
    "    \n",
    "    if not pd.isna(first_row[\"base_model\"]):\n",
    "        base_model = first_row[\"base_model\"]\n",
    "        if \"/\" in base_model:\n",
    "            base_model = base_model.split(\"/\")[1]\n",
    "        g.add((model_uri, KG.base_model, Literal(base_model)))\n",
    "    \n",
    "    language_string = first_row[\"language\"]\n",
    "    if not pd.isna(language_string) and language_string.strip():\n",
    "        language_list = [lang.strip() for lang in language_string.split(\",\") if lang.strip()]\n",
    "        for lang in language_list:\n",
    "            g.add((model_uri, KG.language, Literal(lang)))\n",
    "    \n",
    "    # Process evaluation metrics for each row in the group (if metrics vary per row)\n",
    "    for idx, row in group.iterrows():\n",
    "        metrics_list = json.loads(row[\"evaluation_metrics\"])\n",
    "        for metric in metrics_list:\n",
    "            metric_uri = URIRef(KG + \"EvaluationMetric_\" + str(uuid.uuid4()))\n",
    "            g.add((metric_uri, RDF.type, KG.EvaluationMetric))\n",
    "            g.add((metric_uri, KG.taskType, Literal(metric[\"task_type\"])))\n",
    "            g.add((metric_uri, KG.datasetName, Literal(metric[\"dataset_name\"])))\n",
    "            if metric.get(\"metric_type\"):\n",
    "                g.add((metric_uri, KG.metricType, Literal(metric[\"metric_type\"])))\n",
    "            if metric.get(\"metric_value\"):\n",
    "                g.add((metric_uri, KG.metricValue, Literal(metric[\"metric_value\"], datatype=XSD.float)))\n",
    "            else:\n",
    "                if metric.get(\"metric_mean\"):\n",
    "                    g.add((metric_uri, KG.metricMean, Literal(metric[\"metric_mean\"], datatype=XSD.float)))\n",
    "                if metric.get(\"metric_error\"):\n",
    "                    g.add((metric_uri, KG.metricError, Literal(metric[\"metric_error\"], datatype=XSD.float)))\n",
    "            g.add((model_uri, KG.hasEvaluationMetric, metric_uri))\n",
    "    \n",
    "    # Process paper linking for the entire group (unique papers across rows)\n",
    "    # Process paper linking for the entire group (unique papers across rows)\n",
    "    unique_papers = group['id_y'].dropna().unique()  # paper_info id column\n",
    "    for paper_id in unique_papers:\n",
    "        paper_id_str = str(paper_id).strip()\n",
    "        if paper_id_str == \"\":\n",
    "            continue\n",
    "        if paper_id_str not in paper_resources:\n",
    "            paper_uri = URIRef(KG + \"Paper_\" + paper_id_str)\n",
    "            paper_resources[paper_id_str] = paper_uri\n",
    "            g.add((paper_uri, RDF.type, KG.Paper))\n",
    "            g.add((paper_uri, BIBO.identifier, Literal(paper_id_str)))\n",
    "            authors = group.iloc[0].get(\"authors\")\n",
    "            if pd.notna(authors):\n",
    "                authors = authors.strip()\n",
    "                g.add((paper_uri, BIBO.authorList, Literal(authors)))\n",
    "            title = group.iloc[0].get(\"title\")\n",
    "            if pd.notna(title):\n",
    "                title = title.strip()\n",
    "                g.add((paper_uri, BIBO.title, Literal(title, lang=\"en\")))\n",
    "            summary = group.iloc[0].get(\"summary\")  \n",
    "            if pd.notna(summary) and summary.strip():\n",
    "                g.add((paper_uri, BIBO.abstract, Literal(summary, lang=\"en\")))\n",
    "        else:\n",
    "            paper_uri = paper_resources[paper_id_str]\n",
    "        # Link the model to the paper\n",
    "        g.add((model_uri, KG.hasPaper, paper_uri))\n",
    "\n",
    "g.serialize(destination=\"./output/graph/models-metrics-papers.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3674\n"
     ]
    }
   ],
   "source": [
    "print(len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id_x",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "downloads",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pipeline_tag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "arxiv_ids",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "base_model",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "language",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "evaluation_metrics",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "id_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "12db788d-c230-4b2a-972c-700b1e0ae98e",
       "rows": [
        [
         "9572",
         "1aurent/vit_base_patch16_224.owkin_pancancer",
         "1aurent",
         "2023-10-22T22:56:17",
         "110",
         "feature-extraction",
         null,
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"Camelyon16[Meta]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"94.5\", \"metric_error\": 4.4}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA[Hist]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"96.2\", \"metric_error\": 3.3}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA[HRD]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"79.3\", \"metric_error\": 2.4}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA[Mol]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"81.7\", \"metric_error\": 1.6}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"64.7\", \"metric_error\": 5.7}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-CRC[MSI]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"91.0\", \"metric_error\": 2.2}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-COAD[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"63.4\", \"metric_error\": 7.4}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-NSCLC[CType]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"97.7\", \"metric_error\": 1.3}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-LUAD[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"53.8\", \"metric_error\": 4.5}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-LUSC[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"62.2\", \"metric_error\": 2.9}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-OV[HRD]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"74.2\", \"metric_error\": 8.6}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-RCC[CType]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"99.5\", \"metric_error\": 0.2}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-STAD[MSI]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"89.9\", \"metric_error\": 3.9}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-PAAD[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"59.2\", \"metric_error\": 4.1}]",
         null,
         null,
         null,
         null
        ],
        [
         "9653",
         "1aurent/vit_base_patch16_224.owkin_pancancer_ft_kather2016",
         "1aurent",
         "2023-10-27T16:52:29",
         "28",
         "image-classification",
         null,
         "1aurent/vit_base_patch16_224.owkin_pancancer",
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"1aurent/Kather-texture-2016\", \"metric_type\": \"accuracy\", \"metric_value\": 0.984}]",
         null,
         null,
         null,
         null
        ],
        [
         "9663",
         "1aurent/resnet50.tcga_brca_simclr",
         "1aurent",
         "2023-10-28T13:33:20",
         "46",
         "feature-extraction",
         "arxiv:2203.00585",
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA\", \"metric_type\": \"accuracy\", \"metric_mean\": \"0.879\", \"metric_error\": 0.069}]",
         "2203.00585",
         "Richard J. Chen, Rahul G. Krishnan",
         "Self-Supervised Vision Transformers Learn Visual Concepts in\n  Histopathology",
         "Tissue phenotyping is a fundamental task in learning objective\ncharacterizations of histopathologic biomarkers within the tumor-immune\nmicroenvironment in cancer pathology. However, whole-slide imaging (WSI) is a\ncomplex computer vision in which: 1) WSIs have enormous image resolutions with\nprecludes large-scale pixel-level efforts in data curation, and 2) diversity of\nmorphological phenotypes results in inter- and intra-observer variability in\ntissue labeling. To address these limitations, current efforts have proposed\nusing pretrained image encoders (transfer learning from ImageNet,\nself-supervised pretraining) in extracting morphological features from\npathology, but have not been extensively validated. In this work, we conduct a\nsearch for good representations in pathology by training a variety of\nself-supervised models with validation on a variety of weakly-supervised and\npatch-level tasks. Our key finding is in discovering that Vision Transformers\nusing DINO-based knowledge distillation are able to learn data-efficient and\ninterpretable features in histology images wherein the different attention\nheads learn distinct morphological phenotypes. We make evaluation code and\npretrained weights publicly-available at:\nhttps://github.com/Richarizardd/Self-Supervised-ViT-Path."
        ],
        [
         "9664",
         "1aurent/vit_small_patch16_256.tcga_brca_dino",
         "1aurent",
         "2023-10-28T14:42:11",
         "41",
         "feature-extraction",
         "arxiv:2203.00585",
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA\", \"metric_type\": \"accuracy\", \"metric_mean\": \"0.886\", \"metric_error\": 0.059}]",
         "2203.00585",
         "Richard J. Chen, Rahul G. Krishnan",
         "Self-Supervised Vision Transformers Learn Visual Concepts in\n  Histopathology",
         "Tissue phenotyping is a fundamental task in learning objective\ncharacterizations of histopathologic biomarkers within the tumor-immune\nmicroenvironment in cancer pathology. However, whole-slide imaging (WSI) is a\ncomplex computer vision in which: 1) WSIs have enormous image resolutions with\nprecludes large-scale pixel-level efforts in data curation, and 2) diversity of\nmorphological phenotypes results in inter- and intra-observer variability in\ntissue labeling. To address these limitations, current efforts have proposed\nusing pretrained image encoders (transfer learning from ImageNet,\nself-supervised pretraining) in extracting morphological features from\npathology, but have not been extensively validated. In this work, we conduct a\nsearch for good representations in pathology by training a variety of\nself-supervised models with validation on a variety of weakly-supervised and\npatch-level tasks. Our key finding is in discovering that Vision Transformers\nusing DINO-based knowledge distillation are able to learn data-efficient and\ninterpretable features in histology images wherein the different attention\nheads learn distinct morphological phenotypes. We make evaluation code and\npretrained weights publicly-available at:\nhttps://github.com/Richarizardd/Self-Supervised-ViT-Path."
        ],
        [
         "9702",
         "1aurent/swin_tiny_patch4_window7_224.CTransPath",
         "1aurent",
         "2023-10-31T01:25:20",
         "2176",
         "feature-extraction",
         null,
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"Camelyon16[Meta]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"96.3\", \"metric_error\": 2.6}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA[Hist]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"95.8\", \"metric_error\": 0.5}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA[HRD]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"77.1\", \"metric_error\": 2.5}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA[Mol]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"80.8\", \"metric_error\": 1.7}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-BRCA[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"65.0\", \"metric_error\": 6.0}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-CRC[MSI]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"88.5\", \"metric_error\": 2.3}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-COAD[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"64.3\", \"metric_error\": 5.4}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-NSCLC[CType]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"97.3\", \"metric_error\": 0.4}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-LUAD[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"59.1\", \"metric_error\": 4.5}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-LUSC[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"61.5\", \"metric_error\": 2.9}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-OV[HRD]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"69.5\", \"metric_error\": 7.0}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-RCC[CType]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"98.9\", \"metric_error\": 0.2}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-STAD[MSI]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"83.2\", \"metric_error\": 8.1}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TCGA-PAAD[OS]\", \"metric_type\": \"accuracy\", \"metric_mean\": \"59.0\", \"metric_error\": 4.2}]",
         null,
         null,
         null,
         null
        ],
        [
         "9826",
         "1aurent/phikon-finetuned-lora-kather2016",
         "1aurent",
         "2023-11-08T19:42:56",
         "13",
         "image-classification",
         null,
         "owkin/phikon",
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"1aurent/Kather-texture-2016\", \"metric_type\": \"accuracy\", \"metric_value\": 0.99}]",
         null,
         null,
         null,
         null
        ],
        [
         "9830",
         "1aurent/phikon-distil-mobilenet_v2-kather2016",
         "1aurent",
         "2023-11-09T10:16:17",
         "235",
         "image-classification",
         null,
         "1aurent/phikon-finetuned-lora-kather2016",
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"1aurent/Kather-texture-2016\", \"metric_type\": \"accuracy\", \"metric_value\": 0.928}]",
         null,
         null,
         null,
         null
        ],
        [
         "9832",
         "1aurent/phikon-distil-vit-tiny-patch16-224-kather2016",
         "1aurent",
         "2023-11-09T11:00:55",
         "254",
         "image-classification",
         null,
         "1aurent/phikon-finetuned-lora-kather2016",
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"1aurent/Kather-texture-2016\", \"metric_type\": \"accuracy\", \"metric_value\": 0.932}]",
         null,
         null,
         null,
         null
        ],
        [
         "13928",
         "1aurent/vit_small_patch16_224.kaiko_ai_towards_large_pathology_fms",
         "1aurent",
         "2024-06-07T20:17:03",
         "119",
         "feature-extraction",
         "arxiv:2404.15217",
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"BACH\", \"metric_type\": \"accuracy\", \"metric_value\": 0.797}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CRC-NCT-HE\", \"metric_type\": \"accuracy\", \"metric_value\": 0.943}, {\"task_type\": \"image-classification\", \"dataset_name\": \"MHIST\", \"metric_type\": \"accuracy\", \"metric_value\": 0.828}, {\"task_type\": \"image-classification\", \"dataset_name\": \"PCam\", \"metric_type\": \"accuracy\", \"metric_value\": 0.893}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TP53\", \"metric_type\": \"accuracy\", \"metric_value\": 0.633}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CoNSeP\", \"metric_type\": \"accuracy\", \"metric_value\": 0.649}]",
         "2404.15217",
         "kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioannis Gatopoulos, Nicolas Känzig, Mikhail Karasikov, Axel Lagré, Roman Moser, Joost van Doorn, Fei Tang",
         "Towards Large-Scale Training of Pathology Foundation Models",
         "Driven by the recent advances in deep learning methods and, in particular, by\nthe development of modern self-supervised learning algorithms, increased\ninterest and efforts have been devoted to build foundation models (FMs) for\nmedical images. In this work, we present our scalable training pipeline for\nlarge pathology imaging data, and a comprehensive analysis of various\nhyperparameter choices and training techniques for building pathology FMs. We\nrelease and make publicly available the first batch of our pathology FMs\n(https://github.com/kaiko-ai/towards_large_pathology_fms) trained on\nopen-access TCGA whole slide images, a commonly used collection of pathology\nimages. The experimental evaluation shows that our models reach\nstate-of-the-art performance on various patch-level downstream tasks, ranging\nfrom breast cancer subtyping to colorectal nuclear segmentation. Finally, to\nunify the evaluation approaches used in the field and to simplify future\ncomparisons of different FMs, we present an open-source framework\n(https://github.com/kaiko-ai/eva) designed for the consistent evaluation of\npathology FMs across various downstream tasks."
        ],
        [
         "13929",
         "1aurent/vit_small_patch8_224.kaiko_ai_towards_large_pathology_fms",
         "1aurent",
         "2024-06-07T20:19:59",
         "138",
         "feature-extraction",
         "arxiv:2404.15217",
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"BACH\", \"metric_type\": \"accuracy\", \"metric_value\": 0.834}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CRC-NCT-HE\", \"metric_type\": \"accuracy\", \"metric_value\": 0.946}, {\"task_type\": \"image-classification\", \"dataset_name\": \"MHIST\", \"metric_type\": \"accuracy\", \"metric_value\": 0.832}, {\"task_type\": \"image-classification\", \"dataset_name\": \"PCam\", \"metric_type\": \"accuracy\", \"metric_value\": 0.887}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TP53\", \"metric_type\": \"accuracy\", \"metric_value\": 0.621}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CoNSeP\", \"metric_type\": \"accuracy\", \"metric_value\": 0.724}]",
         "2404.15217",
         "kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioannis Gatopoulos, Nicolas Känzig, Mikhail Karasikov, Axel Lagré, Roman Moser, Joost van Doorn, Fei Tang",
         "Towards Large-Scale Training of Pathology Foundation Models",
         "Driven by the recent advances in deep learning methods and, in particular, by\nthe development of modern self-supervised learning algorithms, increased\ninterest and efforts have been devoted to build foundation models (FMs) for\nmedical images. In this work, we present our scalable training pipeline for\nlarge pathology imaging data, and a comprehensive analysis of various\nhyperparameter choices and training techniques for building pathology FMs. We\nrelease and make publicly available the first batch of our pathology FMs\n(https://github.com/kaiko-ai/towards_large_pathology_fms) trained on\nopen-access TCGA whole slide images, a commonly used collection of pathology\nimages. The experimental evaluation shows that our models reach\nstate-of-the-art performance on various patch-level downstream tasks, ranging\nfrom breast cancer subtyping to colorectal nuclear segmentation. Finally, to\nunify the evaluation approaches used in the field and to simplify future\ncomparisons of different FMs, we present an open-source framework\n(https://github.com/kaiko-ai/eva) designed for the consistent evaluation of\npathology FMs across various downstream tasks."
        ],
        [
         "13930",
         "1aurent/vit_base_patch16_224.kaiko_ai_towards_large_pathology_fms",
         "1aurent",
         "2024-06-07T20:22:40",
         "2425",
         "feature-extraction",
         "arxiv:2404.15217",
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"BACH\", \"metric_type\": \"accuracy\", \"metric_value\": 0.81}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CRC-NCT-HE\", \"metric_type\": \"accuracy\", \"metric_value\": 0.96}, {\"task_type\": \"image-classification\", \"dataset_name\": \"MHIST\", \"metric_type\": \"accuracy\", \"metric_value\": 0.826}, {\"task_type\": \"image-classification\", \"dataset_name\": \"PCam\", \"metric_type\": \"accuracy\", \"metric_value\": 0.898}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TP53\", \"metric_type\": \"accuracy\", \"metric_value\": 0.651}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CoNSeP\", \"metric_type\": \"accuracy\", \"metric_value\": 0.658}]",
         "2404.15217",
         "kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioannis Gatopoulos, Nicolas Känzig, Mikhail Karasikov, Axel Lagré, Roman Moser, Joost van Doorn, Fei Tang",
         "Towards Large-Scale Training of Pathology Foundation Models",
         "Driven by the recent advances in deep learning methods and, in particular, by\nthe development of modern self-supervised learning algorithms, increased\ninterest and efforts have been devoted to build foundation models (FMs) for\nmedical images. In this work, we present our scalable training pipeline for\nlarge pathology imaging data, and a comprehensive analysis of various\nhyperparameter choices and training techniques for building pathology FMs. We\nrelease and make publicly available the first batch of our pathology FMs\n(https://github.com/kaiko-ai/towards_large_pathology_fms) trained on\nopen-access TCGA whole slide images, a commonly used collection of pathology\nimages. The experimental evaluation shows that our models reach\nstate-of-the-art performance on various patch-level downstream tasks, ranging\nfrom breast cancer subtyping to colorectal nuclear segmentation. Finally, to\nunify the evaluation approaches used in the field and to simplify future\ncomparisons of different FMs, we present an open-source framework\n(https://github.com/kaiko-ai/eva) designed for the consistent evaluation of\npathology FMs across various downstream tasks."
        ],
        [
         "13931",
         "1aurent/vit_base_patch8_224.kaiko_ai_towards_large_pathology_fms",
         "1aurent",
         "2024-06-07T20:23:52",
         "192",
         "feature-extraction",
         "arxiv:2404.15217",
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"BACH\", \"metric_type\": \"accuracy\", \"metric_value\": 0.865}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CRC-NCT-HE\", \"metric_type\": \"accuracy\", \"metric_value\": 0.956}, {\"task_type\": \"image-classification\", \"dataset_name\": \"MHIST\", \"metric_type\": \"accuracy\", \"metric_value\": 0.809}, {\"task_type\": \"image-classification\", \"dataset_name\": \"PCam\", \"metric_type\": \"accuracy\", \"metric_value\": 0.921}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TP53\", \"metric_type\": \"accuracy\", \"metric_value\": 0.659}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CoNSeP\", \"metric_type\": \"accuracy\", \"metric_value\": 0.741}]",
         "2404.15217",
         "kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioannis Gatopoulos, Nicolas Känzig, Mikhail Karasikov, Axel Lagré, Roman Moser, Joost van Doorn, Fei Tang",
         "Towards Large-Scale Training of Pathology Foundation Models",
         "Driven by the recent advances in deep learning methods and, in particular, by\nthe development of modern self-supervised learning algorithms, increased\ninterest and efforts have been devoted to build foundation models (FMs) for\nmedical images. In this work, we present our scalable training pipeline for\nlarge pathology imaging data, and a comprehensive analysis of various\nhyperparameter choices and training techniques for building pathology FMs. We\nrelease and make publicly available the first batch of our pathology FMs\n(https://github.com/kaiko-ai/towards_large_pathology_fms) trained on\nopen-access TCGA whole slide images, a commonly used collection of pathology\nimages. The experimental evaluation shows that our models reach\nstate-of-the-art performance on various patch-level downstream tasks, ranging\nfrom breast cancer subtyping to colorectal nuclear segmentation. Finally, to\nunify the evaluation approaches used in the field and to simplify future\ncomparisons of different FMs, we present an open-source framework\n(https://github.com/kaiko-ai/eva) designed for the consistent evaluation of\npathology FMs across various downstream tasks."
        ],
        [
         "13932",
         "1aurent/vit_large_patch14_reg4_224.kaiko_ai_towards_large_pathology_fms",
         "1aurent",
         "2024-06-07T20:24:11",
         "124",
         "feature-extraction",
         "arxiv:2404.15217",
         null,
         null,
         "[{\"task_type\": \"image-classification\", \"dataset_name\": \"BACH\", \"metric_type\": \"accuracy\", \"metric_value\": 0.87}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CRC-NCT-HE\", \"metric_type\": \"accuracy\", \"metric_value\": 0.93}, {\"task_type\": \"image-classification\", \"dataset_name\": \"MHIST\", \"metric_type\": \"accuracy\", \"metric_value\": 0.809}, {\"task_type\": \"image-classification\", \"dataset_name\": \"PCam\", \"metric_type\": \"accuracy\", \"metric_value\": 0.898}, {\"task_type\": \"image-classification\", \"dataset_name\": \"TP53\", \"metric_type\": \"accuracy\", \"metric_value\": 0.656}, {\"task_type\": \"image-classification\", \"dataset_name\": \"CoNSeP\", \"metric_type\": \"accuracy\", \"metric_value\": 0.679}]",
         "2404.15217",
         "kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioannis Gatopoulos, Nicolas Känzig, Mikhail Karasikov, Axel Lagré, Roman Moser, Joost van Doorn, Fei Tang",
         "Towards Large-Scale Training of Pathology Foundation Models",
         "Driven by the recent advances in deep learning methods and, in particular, by\nthe development of modern self-supervised learning algorithms, increased\ninterest and efforts have been devoted to build foundation models (FMs) for\nmedical images. In this work, we present our scalable training pipeline for\nlarge pathology imaging data, and a comprehensive analysis of various\nhyperparameter choices and training techniques for building pathology FMs. We\nrelease and make publicly available the first batch of our pathology FMs\n(https://github.com/kaiko-ai/towards_large_pathology_fms) trained on\nopen-access TCGA whole slide images, a commonly used collection of pathology\nimages. The experimental evaluation shows that our models reach\nstate-of-the-art performance on various patch-level downstream tasks, ranging\nfrom breast cancer subtyping to colorectal nuclear segmentation. Finally, to\nunify the evaluation approaches used in the field and to simplify future\ncomparisons of different FMs, we present an open-source framework\n(https://github.com/kaiko-ai/eva) designed for the consistent evaluation of\npathology FMs across various downstream tasks."
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>arxiv_ids</th>\n",
       "      <th>base_model</th>\n",
       "      <th>language</th>\n",
       "      <th>evaluation_metrics</th>\n",
       "      <th>id_y</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9572</th>\n",
       "      <td>1aurent/vit_base_patch16_224.owkin_pancancer</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2023-10-22T22:56:17</td>\n",
       "      <td>110</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9653</th>\n",
       "      <td>1aurent/vit_base_patch16_224.owkin_pancancer_f...</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2023-10-27T16:52:29</td>\n",
       "      <td>28</td>\n",
       "      <td>image-classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1aurent/vit_base_patch16_224.owkin_pancancer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9663</th>\n",
       "      <td>1aurent/resnet50.tcga_brca_simclr</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2023-10-28T13:33:20</td>\n",
       "      <td>46</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>arxiv:2203.00585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>2203.00585</td>\n",
       "      <td>Richard J. Chen, Rahul G. Krishnan</td>\n",
       "      <td>Self-Supervised Vision Transformers Learn Visu...</td>\n",
       "      <td>Tissue phenotyping is a fundamental task in le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9664</th>\n",
       "      <td>1aurent/vit_small_patch16_256.tcga_brca_dino</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2023-10-28T14:42:11</td>\n",
       "      <td>41</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>arxiv:2203.00585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>2203.00585</td>\n",
       "      <td>Richard J. Chen, Rahul G. Krishnan</td>\n",
       "      <td>Self-Supervised Vision Transformers Learn Visu...</td>\n",
       "      <td>Tissue phenotyping is a fundamental task in le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9702</th>\n",
       "      <td>1aurent/swin_tiny_patch4_window7_224.CTransPath</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2023-10-31T01:25:20</td>\n",
       "      <td>2176</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9826</th>\n",
       "      <td>1aurent/phikon-finetuned-lora-kather2016</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2023-11-08T19:42:56</td>\n",
       "      <td>13</td>\n",
       "      <td>image-classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>owkin/phikon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9830</th>\n",
       "      <td>1aurent/phikon-distil-mobilenet_v2-kather2016</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2023-11-09T10:16:17</td>\n",
       "      <td>235</td>\n",
       "      <td>image-classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1aurent/phikon-finetuned-lora-kather2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>1aurent/phikon-distil-vit-tiny-patch16-224-kat...</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2023-11-09T11:00:55</td>\n",
       "      <td>254</td>\n",
       "      <td>image-classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1aurent/phikon-finetuned-lora-kather2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13928</th>\n",
       "      <td>1aurent/vit_small_patch16_224.kaiko_ai_towards...</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2024-06-07T20:17:03</td>\n",
       "      <td>119</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>arxiv:2404.15217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>2404.15217</td>\n",
       "      <td>kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...</td>\n",
       "      <td>Towards Large-Scale Training of Pathology Foun...</td>\n",
       "      <td>Driven by the recent advances in deep learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13929</th>\n",
       "      <td>1aurent/vit_small_patch8_224.kaiko_ai_towards_...</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2024-06-07T20:19:59</td>\n",
       "      <td>138</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>arxiv:2404.15217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>2404.15217</td>\n",
       "      <td>kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...</td>\n",
       "      <td>Towards Large-Scale Training of Pathology Foun...</td>\n",
       "      <td>Driven by the recent advances in deep learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13930</th>\n",
       "      <td>1aurent/vit_base_patch16_224.kaiko_ai_towards_...</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2024-06-07T20:22:40</td>\n",
       "      <td>2425</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>arxiv:2404.15217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>2404.15217</td>\n",
       "      <td>kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...</td>\n",
       "      <td>Towards Large-Scale Training of Pathology Foun...</td>\n",
       "      <td>Driven by the recent advances in deep learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13931</th>\n",
       "      <td>1aurent/vit_base_patch8_224.kaiko_ai_towards_l...</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2024-06-07T20:23:52</td>\n",
       "      <td>192</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>arxiv:2404.15217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>2404.15217</td>\n",
       "      <td>kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...</td>\n",
       "      <td>Towards Large-Scale Training of Pathology Foun...</td>\n",
       "      <td>Driven by the recent advances in deep learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13932</th>\n",
       "      <td>1aurent/vit_large_patch14_reg4_224.kaiko_ai_to...</td>\n",
       "      <td>1aurent</td>\n",
       "      <td>2024-06-07T20:24:11</td>\n",
       "      <td>124</td>\n",
       "      <td>feature-extraction</td>\n",
       "      <td>arxiv:2404.15217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"task_type\": \"image-classification\", \"datase...</td>\n",
       "      <td>2404.15217</td>\n",
       "      <td>kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...</td>\n",
       "      <td>Towards Large-Scale Training of Pathology Foun...</td>\n",
       "      <td>Driven by the recent advances in deep learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id_x   author  \\\n",
       "9572        1aurent/vit_base_patch16_224.owkin_pancancer  1aurent   \n",
       "9653   1aurent/vit_base_patch16_224.owkin_pancancer_f...  1aurent   \n",
       "9663                   1aurent/resnet50.tcga_brca_simclr  1aurent   \n",
       "9664        1aurent/vit_small_patch16_256.tcga_brca_dino  1aurent   \n",
       "9702     1aurent/swin_tiny_patch4_window7_224.CTransPath  1aurent   \n",
       "9826            1aurent/phikon-finetuned-lora-kather2016  1aurent   \n",
       "9830       1aurent/phikon-distil-mobilenet_v2-kather2016  1aurent   \n",
       "9832   1aurent/phikon-distil-vit-tiny-patch16-224-kat...  1aurent   \n",
       "13928  1aurent/vit_small_patch16_224.kaiko_ai_towards...  1aurent   \n",
       "13929  1aurent/vit_small_patch8_224.kaiko_ai_towards_...  1aurent   \n",
       "13930  1aurent/vit_base_patch16_224.kaiko_ai_towards_...  1aurent   \n",
       "13931  1aurent/vit_base_patch8_224.kaiko_ai_towards_l...  1aurent   \n",
       "13932  1aurent/vit_large_patch14_reg4_224.kaiko_ai_to...  1aurent   \n",
       "\n",
       "                created_at  downloads          pipeline_tag         arxiv_ids  \\\n",
       "9572   2023-10-22T22:56:17        110    feature-extraction               NaN   \n",
       "9653   2023-10-27T16:52:29         28  image-classification               NaN   \n",
       "9663   2023-10-28T13:33:20         46    feature-extraction  arxiv:2203.00585   \n",
       "9664   2023-10-28T14:42:11         41    feature-extraction  arxiv:2203.00585   \n",
       "9702   2023-10-31T01:25:20       2176    feature-extraction               NaN   \n",
       "9826   2023-11-08T19:42:56         13  image-classification               NaN   \n",
       "9830   2023-11-09T10:16:17        235  image-classification               NaN   \n",
       "9832   2023-11-09T11:00:55        254  image-classification               NaN   \n",
       "13928  2024-06-07T20:17:03        119    feature-extraction  arxiv:2404.15217   \n",
       "13929  2024-06-07T20:19:59        138    feature-extraction  arxiv:2404.15217   \n",
       "13930  2024-06-07T20:22:40       2425    feature-extraction  arxiv:2404.15217   \n",
       "13931  2024-06-07T20:23:52        192    feature-extraction  arxiv:2404.15217   \n",
       "13932  2024-06-07T20:24:11        124    feature-extraction  arxiv:2404.15217   \n",
       "\n",
       "                                         base_model language  \\\n",
       "9572                                            NaN      NaN   \n",
       "9653   1aurent/vit_base_patch16_224.owkin_pancancer      NaN   \n",
       "9663                                            NaN      NaN   \n",
       "9664                                            NaN      NaN   \n",
       "9702                                            NaN      NaN   \n",
       "9826                                   owkin/phikon      NaN   \n",
       "9830       1aurent/phikon-finetuned-lora-kather2016      NaN   \n",
       "9832       1aurent/phikon-finetuned-lora-kather2016      NaN   \n",
       "13928                                           NaN      NaN   \n",
       "13929                                           NaN      NaN   \n",
       "13930                                           NaN      NaN   \n",
       "13931                                           NaN      NaN   \n",
       "13932                                           NaN      NaN   \n",
       "\n",
       "                                      evaluation_metrics        id_y  \\\n",
       "9572   [{\"task_type\": \"image-classification\", \"datase...         NaN   \n",
       "9653   [{\"task_type\": \"image-classification\", \"datase...         NaN   \n",
       "9663   [{\"task_type\": \"image-classification\", \"datase...  2203.00585   \n",
       "9664   [{\"task_type\": \"image-classification\", \"datase...  2203.00585   \n",
       "9702   [{\"task_type\": \"image-classification\", \"datase...         NaN   \n",
       "9826   [{\"task_type\": \"image-classification\", \"datase...         NaN   \n",
       "9830   [{\"task_type\": \"image-classification\", \"datase...         NaN   \n",
       "9832   [{\"task_type\": \"image-classification\", \"datase...         NaN   \n",
       "13928  [{\"task_type\": \"image-classification\", \"datase...  2404.15217   \n",
       "13929  [{\"task_type\": \"image-classification\", \"datase...  2404.15217   \n",
       "13930  [{\"task_type\": \"image-classification\", \"datase...  2404.15217   \n",
       "13931  [{\"task_type\": \"image-classification\", \"datase...  2404.15217   \n",
       "13932  [{\"task_type\": \"image-classification\", \"datase...  2404.15217   \n",
       "\n",
       "                                                 authors  \\\n",
       "9572                                                 NaN   \n",
       "9653                                                 NaN   \n",
       "9663                  Richard J. Chen, Rahul G. Krishnan   \n",
       "9664                  Richard J. Chen, Rahul G. Krishnan   \n",
       "9702                                                 NaN   \n",
       "9826                                                 NaN   \n",
       "9830                                                 NaN   \n",
       "9832                                                 NaN   \n",
       "13928  kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...   \n",
       "13929  kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...   \n",
       "13930  kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...   \n",
       "13931  kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...   \n",
       "13932  kaiko. ai, Nanne Aben, Edwin D. de Jong, Ioann...   \n",
       "\n",
       "                                                   title  \\\n",
       "9572                                                 NaN   \n",
       "9653                                                 NaN   \n",
       "9663   Self-Supervised Vision Transformers Learn Visu...   \n",
       "9664   Self-Supervised Vision Transformers Learn Visu...   \n",
       "9702                                                 NaN   \n",
       "9826                                                 NaN   \n",
       "9830                                                 NaN   \n",
       "9832                                                 NaN   \n",
       "13928  Towards Large-Scale Training of Pathology Foun...   \n",
       "13929  Towards Large-Scale Training of Pathology Foun...   \n",
       "13930  Towards Large-Scale Training of Pathology Foun...   \n",
       "13931  Towards Large-Scale Training of Pathology Foun...   \n",
       "13932  Towards Large-Scale Training of Pathology Foun...   \n",
       "\n",
       "                                                 summary  \n",
       "9572                                                 NaN  \n",
       "9653                                                 NaN  \n",
       "9663   Tissue phenotyping is a fundamental task in le...  \n",
       "9664   Tissue phenotyping is a fundamental task in le...  \n",
       "9702                                                 NaN  \n",
       "9826                                                 NaN  \n",
       "9830                                                 NaN  \n",
       "9832                                                 NaN  \n",
       "13928  Driven by the recent advances in deep learning...  \n",
       "13929  Driven by the recent advances in deep learning...  \n",
       "13930  Driven by the recent advances in deep learning...  \n",
       "13931  Driven by the recent advances in deep learning...  \n",
       "13932  Driven by the recent advances in deep learning...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[merged[\"author\"]== \"1aurent\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
